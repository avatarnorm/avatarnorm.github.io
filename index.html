<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>HumanNorm</title>
<link href="./js/style.css" rel="stylesheet">
<script type="text/javascript" src="./js/jquery.mlens-1.0.min.js"></script>
<script type="text/javascript" src="./js/jquery.js"></script>


<style>
  p.serif{
    font-family:"Times New Roman", Times, serif;
  }
  p.sansserif{
    font-family: Arial, Helvetica, sans-serif;
  }
  .text-center {
    text-align: center;
}
</style>
  
</head>

<body>
<div class="content">
  <h1><strong>Human<span style="color: #036bfc;">N</span><span style="color: #3503fc;">o</span><span style="color: #a200ff;">r</span><span style="color: #e250ff;">m</span>: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation</strong></h1>
  <p id="authors"><a href="https://xhuangcv.github.io/">Xin Huang<sup>*,&dagger;,1</sup></a> <a href="https://dsaurus.github.io/saurus/">Ruizhi Shao<sup>*,2</sup></a> <a href="https://qzhang-cv.github.io/">Qi Zhang<sup>1</sup></a> <a href="https://zhanghongwen.cn/">Hongwen Zhang<sup>2</sup></a> <a href="https://scholar.google.com/citations?user=PhkrqioAAAAJ&hl=en">Ying Feng<sup>1</sup></a> </p>
  <p id="authors"><a href="https://www.liuyebin.com/">Yebin Liu<sup>2</sup></a> <a href="https://teacher.nwpu.edu.cn/qwang.html ">Qing Wang<sup>1</sup></a> <br>
    <br>
  <span style="font-size: 24px"><sup>1</sup>Northwestern Polytechnical University &nbsp;
  </span>
  <span style="font-size: 24px">
    <sup>2</sup>Tsinghua University
 </span><br>
 <span style="font-size: 18px"><sup>*</sup>Equal Contribution, &nbsp; <sup>&dagger;</sup>Work done during an internship at Tsinghua University
 </span></p>
 <br>
 

  <div class="row">
    <div class="col-full">
      <img class="summary-img" src="figs/teaser.png" style="width:100%;">
    </div>
  </div>
  
  <h3 style="text-align:center"><em>Given a prompt, our method is capable of generating a high-quality and realistic 3D human...</em></h3>
  <font size="+2">
    <p style="text-align: center;">
      <a href="https://arxiv.org/abs/2310.01406" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
      <a href="https://mailstsinghuaeducn-my.sharepoint.com/:f:/g/personal/shaorz20_mails_tsinghua_edu_cn/EoJwWzJWp6BEv_SnuTd1rPUBimjlBDiqFcDGrIxT7lH09Q?e=1Axj3i" target="_blank">[Gallery]</a> &nbsp;&nbsp;&nbsp;&nbsp;
      <a href="https://github.com/xhuangcv/humannorm" target="_blank">[Code]</a>
      </p>
  </font>
</div>


<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Methodology</p>
  <p style="font-size: 1.2em" class="serif">
    Our method is designed for high-quality and realistic 3D human generation from given prompts. The whole framework consists of geometry and texture generation. We first propose the normal-adapted and depth-adapted diffusion model for the geometry generation. These two models can guide the rendered normal and depth maps to approach the learned distribution of high-fidelity normal and depth maps through the SDS loss, thereby achieving high-quality geometry generation. In terms of texture generation, we introduce the normal-aligned diffusion model. The normal-aligned diffusion model leverages normal maps as guiding cues to ensure the alignment of the generated texture with geometry. We first exclusively employ the SDS loss and then incorporate the multi-step SDS and perceptual loss to achieve realistic texture generation.
  </p>
  <img class="summary-img" src="figs/pipeline.png" style="width:100%;"> <br>




</div>

<!-- results -->
<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Results -- Head Only & Upper Body </p>
  <p style="font-size: 1.2em" class="serif">
    We showcase 3D humans generated by our method, which include full-body, upper-body, and head-only models.<br>
  </p>



  <div class="row">
    <div class="col-full">
      <video  width="100%" loop controls>
        <source src="results/main_results/head_only_and_upper_body.mp4" type="video/mp4">
      </video>
    </div>
  </div>


</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Results -- Full Body</p>

  <div class="row">
    <div class="col-full">
      <video  width="100%" loop controls>
        <source src="results/main_results/full_body.mp4" type="video/mp4">
      </video>
    </div>
  </div>

  </div>


<!-- comparisons -->
<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Comparisons with Text-to-3D Content Methods</p>

  <div class="row">
    <div class="col-full">
      <video  width="100%" loop controls>
        <source src="results/comparisons/comparison_video_p1.mp4" type="video/mp4">
      </video>
    </div>
  </div>
  </div>


  <div class="content">
    <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Comparisons with Text-to-3D Human Methods</p>
  
    <div class="row">
      <div class="col-full">
        <video  width="100%" loop controls>
          <source src="results/comparisons/comparison_video_p2.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  
    </div>


  <!-- editing -->
<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Applications -- Text-based Editing</p>
  <p style="font-size: 1.2em" class="serif">
    HumanNorm offers the capability to edit both the <b>texture and geometry</b> of the generated 3D humans by adjusting the input prompt.<br>

  </p>

  <div class="row">
    <div class="col-full">
      <video  width="100%" loop autoplay muted>
        <source src="results/editing_videos/textbasedediting.mp4" type="video/mp4">
      </video>
    </div>
  </div>


  </div>


  <div class="content">
    <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Applications -- 3D Animation</p>
    <p style="font-size: 1.2em" class="serif">
      HumanNorm enables the creation of lifelike human mesh featuring about 400K distinct faces and intricate 2K-resolution texture map. Based on the high-quality models, we can animate them using full-body motion sequences. Explore our <a href="https://mailstsinghuaeducn-my.sharepoint.com/:f:/g/personal/shaorz20_mails_tsinghua_edu_cn/EoJwWzJWp6BEv_SnuTd1rPUBimjlBDiqFcDGrIxT7lH09Q?e=1Axj3i">gallery</a> for more generated models.</p>
    </p> 
    <div >
      <div class="row" style="display: flex; justify-content: center;">
        <div class="col">
          <video  height="256px" loop autoplay muted>
            <source src="results/animation/meshlab.mp4" type="video/mp4">
          </video>
          <p class="text-center" ><b>View human model in MeshLab (Shading: None)</b></p>
        </div>
        <div class="col" style="height: 64px; width: 64px;"></div>
        <div class="col" style="height: 256px; width: 256px;">
        <img class="summary-img" src="results/animation/texture_kd.jpg" >
        <p class="text-center"><b>2K-resolution texture map</b></p>
        </div>
      </div>
    </div>

    <div class="row">
      <div class="col-gallery">
        <video  width="100%" loop autoplay muted>
          <source src="results/animation/musk1.mp4" type="video/mp4">
        </video>
      </div>
      <div class="col-gallery">
        <video  width="100%" loop autoplay muted>
          <source src="results/animation/biden1.mp4" type="video/mp4">
        </video>
      </div>
      <div class="col-gallery">
        <video  width="100%" loop autoplay muted>
          <source src="results/animation/boxer1.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <div class="row">
      <div class="col-gallery">
        <video  width="100%" loop autoplay muted>
          <source src="results/animation/musk2.mp4" type="video/mp4">
        </video>
      </div>
      <div class="col-gallery">
        <video  width="100%" loop autoplay muted>
          <source src="results/animation/biden2.mp4" type="video/mp4">
        </video>
      </div>
      <div class="col-gallery">
        <video  width="100%" loop autoplay muted>
          <source src="results/animation/boxer2.mp4" type="video/mp4">
        </video>
      </div>
    </div>

    <p class="text-center"><b>Animation Results</b></p>


</div>
</div>



<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Applications -- Pose Editing</p>
  <p style="font-size: 1.2em" class="serif">
    HumanNorm also provides the ability to edit the pose of generated 3D humans by adjusting the pose of the mesh used for initialization and modifying the prompts.
  </p> 
  <div class="row">
    <div class="col">
      <video  width="100%" loop autoplay muted>
        <source src="results/editing_videos/pose1.mp4" type="video/mp4">
      </video>
      <p class="text-center"><b>a photo of Elon Musk with his hands on his hip</b></p>
    </div>

    <div class="col">
      <video  width="100%" loop autoplay muted>
        <source src="results/editing_videos/pose2.mp4" type="video/mp4">
      </video>
      <p class="text-center"><b>a photo of Elon Musk raising a hand</b></p>
    </div>
  </div>

</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Ethics Statement</p>
  <p>The objective of HumanNorm is to equip users with a powerful tool for creating realistic 3D Human models. Our method allows users to generate 3D Humans based on their specific prompts. However, there is a potential risk that these generated models could be misused to deceive viewers. This problem is not unique to our approach but is prevalent in other generative model methodologies. Moreover, it is of paramount importance to give precedence to diversity in terms of gender, race, and culture. As such, it is absolutely essential for current and future research in the field of generative modeling to consistently address and reassess these considerations.</p>
  <br>
</div>

<div class="content">
  <p style="text-align:left; font-size: 2em; font-weight: bold" class="serif">Citation</p>
  <p>@article{humannorm2023, <br>
    title={HumanNorm: Learning Normal Diffusion Model for High-quality and Realistic 3D Human Generation}, <br>
    author={Huang, Xin and Shao, Ruizhi and Zhang, Qi and Zhang, Hongwen and Feng, Ying and Liu, Yebin and Wang, Qing}, <br>
    journal={arXiv}, <br>
    year={2023} <br>
  }</p>
  <br>
</div>


</body>

<script>
var videos = document.getElementsByClassName("clickplay");
for (var i = 0; i < videos.length; i++) {
  videos[i].addEventListener("click", function() {
    this.play();
  });
  videos[i].addEventListener("ended", function() {
    this.pause();
    this.currentTime = 0;
  });
}

document.querySelectorAll('.info-container').forEach(function(container) {
  container.addEventListener('mouseover', function() {
    var infoText = container.querySelector('.info-text');
    infoText.style.display = 'block';
  });

  container.addEventListener('mouseout', function() {
    var infoText = container.querySelector('.info-text');
    infoText.style.display = 'none';
  });
});
</script>

</html>
